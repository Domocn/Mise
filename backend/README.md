# Mise ðŸ³

A self-hostable recipe app for families. Organize recipes, plan meals, generate shopping lists, and share with your household.

> *Mise* â€” from "mise en place," meaning everything in its place.

## Features

- **Recipe Management** â€” Create, edit, and organize recipes with images, tags, and categories
- **AI Import** â€” Paste any recipe URL and AI extracts it automatically
- **Quick Add** â€” Paste raw text and AI parses it into a structured recipe
- **Batch Import** â€” Import from Paprika, Cookmate, Recipe Keeper, or JSON
- **Meal Planning** â€” Weekly calendar for breakfast, lunch, dinner, and snacks
- **Auto Meal Plan** â€” AI generates a balanced weekly plan from your recipes
- **Shopping Lists** â€” Auto-generate from meal plans or create manually
- **What's in My Fridge** â€” Enter ingredients you have, find matching recipes
- **Family Sharing** â€” Create households and share with family members
- **Recipe Scaling** â€” Adjust servings and ingredients scale automatically
- **Recipe Sharing** â€” Share via link, copy as text, or download recipe cards
- **Calendar Sync** â€” Export to Google Calendar, Apple Calendar, Outlook
- **Dark Mode** â€” System preference detection with manual toggle
- **PWA Support** â€” Install on mobile for app-like experience
- **Push Notifications** â€” Meal reminders and shopping alerts
- **Offline AI** â€” Embedded AI that works without internet

## Quick Start

### Option 1: Docker Compose (Command Line)

```bash
git clone https://github.com/Domocn/Mise.git mise
cd mise
docker-compose up -d
```

Open **http://localhost:3000** and create an account.

### Option 2: Portainer

1. Go to **Stacks** â†’ **Add Stack**
2. Name it `mise`
3. Choose one of:
   - **Upload** â€” Upload the `docker-compose.yml` file
   - **Repository** â€” Enter repo URL, set compose path to `docker-compose.yml`
   - **Web editor** â€” Paste the docker-compose below
4. Click **Deploy the stack**
5. Open **http://your-server:3000**

#### Pull AI Model in Portainer

1. Go to **Containers** â†’ `mise-ollama`
2. Click **Console** â†’ **Connect**
3. Run: `ollama pull llama3`

### Docker Compose File

<details>
<summary>Click to expand docker-compose.yml</summary>

> **Note:** This is the minimal version. The full `docker-compose.yml` in the repo includes OpenPanel analytics if you want usage tracking.

```yaml
version: '3.8'

services:
  mongodb:
    image: mongo:7
    container_name: mise-db
    restart: unless-stopped
    volumes:
      - mongodb_data:/data/db
    environment:
      - MONGO_INITDB_DATABASE=mise
    networks:
      - mise-network

  ollama:
    image: ollama/ollama:latest
    container_name: mise-ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    networks:
      - mise-network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: mise-backend
    restart: unless-stopped
    ports:
      - "8001:8001"
    environment:
      - MONGO_URL=mongodb://mongodb:27017
      - DB_NAME=mise
      - JWT_SECRET=change-this-to-a-random-string
      - CORS_ORIGINS=*
      - LLM_PROVIDER=ollama
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=llama3
      - EMBEDDED_MODELS_PATH=/app/models
    volumes:
      - uploads_data:/app/uploads
      - models_data:/app/models
    depends_on:
      - mongodb
      - ollama
    networks:
      - mise-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - REACT_APP_BACKEND_URL=http://localhost:8001
    container_name: mise-frontend
    restart: unless-stopped
    ports:
      - "3000:80"
    environment:
      - REACT_APP_BACKEND_URL=http://localhost:8001
    depends_on:
      - backend
    networks:
      - mise-network

volumes:
  mongodb_data:
  ollama_data:
  uploads_data:
  models_data:

networks:
  mise-network:
    driver: bridge
```

</details>

## AI Setup

Mise supports three AI providers. Choose one:

### Option 1: Embedded (Easiest)

No setup required. In Settings â†’ AI â†’ select **Embedded (100% Offline)** â†’ choose a model â†’ it downloads automatically.

| Model | Download | RAM Required |
|-------|----------|--------------|
| Phi-3 Mini | 2.2 GB | 4 GB |
| Llama 3.2 3B | 2.0 GB | 4 GB |
| Mistral 7B | 4.4 GB | 8 GB |

### Option 2: Ollama (Faster)

```bash
docker exec mise-ollama ollama pull llama3
```

In Settings â†’ AI â†’ select **Ollama (Local)**.

### Option 3: OpenAI (Cloud)

In Settings â†’ AI â†’ select **OpenAI** â†’ enter your API key.

## Services

| Service | URL | Purpose |
|---------|-----|---------|
| Frontend | http://localhost:3000 | Web app |
| Backend | http://localhost:8001 | API |
| Ollama | http://localhost:11434 | Local LLM |
| MongoDB | localhost:27017 | Database |

## Configuration

Environment variables in `docker-compose.yml`:

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENAI_API_KEY` | â€” | OpenAI API key (if using OpenAI) |
| `OLLAMA_HOST` | http://ollama:11434 | Ollama server URL |
| `JWT_SECRET` | (generated) | Auth token secret |
| `DB_NAME` | mise | MongoDB database name |

## Commands

```bash
# Start
docker-compose up -d

# Stop
docker-compose down

# View logs
docker-compose logs -f

# Rebuild after changes
docker-compose up -d --build

# Reset database
docker-compose down -v
docker-compose up -d
```

## Tech Stack

- **Frontend:** React, Tailwind CSS, shadcn/ui, Framer Motion
- **Backend:** FastAPI, Python
- **Database:** MongoDB
- **AI:** OpenAI, Ollama, GPT4All (embedded)
- **Infrastructure:** Docker, Nginx

## Reverse Proxy (Optional)

If running behind Nginx Proxy Manager, Traefik, or Caddy:

```
Frontend: your-domain.com â†’ localhost:3000
Backend API: your-domain.com/api â†’ localhost:8001
```

Update `REACT_APP_BACKEND_URL` in docker-compose.yml:

```yaml
environment:
  - REACT_APP_BACKEND_URL=https://your-domain.com/api
```

## Troubleshooting

| Issue | Solution |
|-------|----------|
| Can't connect to database | Check if `mise-db` container is running |
| AI features not working | Ensure Ollama has a model: `docker exec mise-ollama ollama list` |
| Frontend shows blank page | Check browser console, verify `REACT_APP_BACKEND_URL` |
| Port already in use | Change ports in docker-compose.yml |

### View Logs

```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f backend
docker-compose logs -f frontend
```

## License

MIT
